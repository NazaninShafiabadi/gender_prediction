{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from data_processing import get_correct_wrong_pred_df, get_category_gender_partition, get_false_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexeme</th>\n",
       "      <th>phon</th>\n",
       "      <th>gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>à-côté</td>\n",
       "      <td>akOte</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>à-coup</td>\n",
       "      <td>aku</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>à-peu-près</td>\n",
       "      <td>apØpʁɛ</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>à-pic</td>\n",
       "      <td>apik</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>à-plat</td>\n",
       "      <td>apla</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30999</th>\n",
       "      <td>zurichois</td>\n",
       "      <td>zyʁikwa</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31000</th>\n",
       "      <td>zydeco</td>\n",
       "      <td>zidəko</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31001</th>\n",
       "      <td>zygoma</td>\n",
       "      <td>zigOma</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31002</th>\n",
       "      <td>zygote</td>\n",
       "      <td>zigɔt</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31003</th>\n",
       "      <td>zyklon</td>\n",
       "      <td>ziklɔ̃</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31004 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lexeme     phon gen\n",
       "0          à-côté    akOte   m\n",
       "1          à-coup      aku   m\n",
       "2      à-peu-près   apØpʁɛ   m\n",
       "3           à-pic     apik   m\n",
       "4          à-plat     apla   m\n",
       "...           ...      ...  ..\n",
       "30999   zurichois  zyʁikwa   m\n",
       "31000      zydeco   zidəko   f\n",
       "31001      zygoma   zigOma   m\n",
       "31002      zygote    zigɔt   m\n",
       "31003      zyklon   ziklɔ̃   m\n",
       "\n",
       "[31004 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlexique = pd.read_csv('../data/nlexique.csv')\n",
    "nlexique = nlexique[['lexeme', 'sg', 'gen']].rename(columns={'sg': 'phon'}).dropna().reset_index(drop=True)\n",
    "nlexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>gen</th>\n",
       "      <th>phon</th>\n",
       "      <th>freq_lex_books</th>\n",
       "      <th>freq_lex_subtitles</th>\n",
       "      <th>freq_frcow</th>\n",
       "      <th>last_process_broad</th>\n",
       "      <th>last_process_narrow</th>\n",
       "      <th>prefix</th>\n",
       "      <th>compound</th>\n",
       "      <th>...</th>\n",
       "      <th>autonomous_base</th>\n",
       "      <th>base_stem_phon</th>\n",
       "      <th>sfx_allomorph</th>\n",
       "      <th>der_stem_phon</th>\n",
       "      <th>edit_distance</th>\n",
       "      <th>pattern</th>\n",
       "      <th>pattern_tf</th>\n",
       "      <th>pattern_rel_tf</th>\n",
       "      <th>base_der_sim</th>\n",
       "      <th>offset_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>berlingue</td>\n",
       "      <td>m</td>\n",
       "      <td>bɛʁ.lɛ̃g</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34</td>\n",
       "      <td>nonconcat</td>\n",
       "      <td>apocope</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corton</td>\n",
       "      <td>m</td>\n",
       "      <td>kɔʁ.tɔ̃</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.03</td>\n",
       "      <td>398</td>\n",
       "      <td>suffix</td>\n",
       "      <td>suffix</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>kuʁ</td>\n",
       "      <td>ɔ̃</td>\n",
       "      <td>kɔʁt</td>\n",
       "      <td>2</td>\n",
       "      <td>_u_~_ɔ_tɔ̃</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.222162783145905</td>\n",
       "      <td>0.158108526129264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dabuche</td>\n",
       "      <td>f</td>\n",
       "      <td>da.byʃ</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>suffix</td>\n",
       "      <td>suffix</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>yʃ</td>\n",
       "      <td>dab</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>faf</td>\n",
       "      <td>m</td>\n",
       "      <td>faf</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.07</td>\n",
       "      <td>3422</td>\n",
       "      <td>nonconcat</td>\n",
       "      <td>apocope</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gail</td>\n",
       "      <td>f</td>\n",
       "      <td>gaj</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2471</td>\n",
       "      <td>simplex</td>\n",
       "      <td>native_simplex</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>palu</td>\n",
       "      <td>m</td>\n",
       "      <td>pa.ly</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1431</td>\n",
       "      <td>nonconcat</td>\n",
       "      <td>apocope</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>talc</td>\n",
       "      <td>m</td>\n",
       "      <td>talk</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2775</td>\n",
       "      <td>simplex</td>\n",
       "      <td>borrowing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>sauvetage</td>\n",
       "      <td>m</td>\n",
       "      <td>sO.və.taʒ</td>\n",
       "      <td>3.72</td>\n",
       "      <td>8.32</td>\n",
       "      <td>60875</td>\n",
       "      <td>suffix</td>\n",
       "      <td>suffix</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>sOv</td>\n",
       "      <td>aʒ</td>\n",
       "      <td>sOvət</td>\n",
       "      <td>2</td>\n",
       "      <td>_~_ətaʒ</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011494252873563</td>\n",
       "      <td>0.252674728631973</td>\n",
       "      <td>0.614848479997584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>plaid</td>\n",
       "      <td>m</td>\n",
       "      <td>plɛd</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2889</td>\n",
       "      <td>simplex</td>\n",
       "      <td>borrowing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>lob</td>\n",
       "      <td>m</td>\n",
       "      <td>lɔb</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2965</td>\n",
       "      <td>simplex</td>\n",
       "      <td>borrowing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4534 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lemma gen       phon  freq_lex_books  freq_lex_subtitles  \\\n",
       "0     berlingue   m   bɛʁ.lɛ̃g            0.34                0.00   \n",
       "1        corton   m    kɔʁ.tɔ̃            0.27                0.03   \n",
       "2       dabuche   f     da.byʃ            0.54                0.00   \n",
       "3           faf   m        faf            0.88                0.07   \n",
       "4          gail   f        gaj            0.61                0.00   \n",
       "...         ...  ..        ...             ...                 ...   \n",
       "4995       palu   m      pa.ly            0.14                0.80   \n",
       "4996       talc   m       talk            1.49                1.40   \n",
       "4997  sauvetage   m  sO.və.taʒ            3.72                8.32   \n",
       "4998      plaid   m       plɛd            1.15                0.34   \n",
       "4999        lob   m        lɔb            0.27                0.04   \n",
       "\n",
       "      freq_frcow last_process_broad last_process_narrow prefix compound  ...  \\\n",
       "0             34          nonconcat             apocope      0        0  ...   \n",
       "1            398             suffix              suffix      0        0  ...   \n",
       "2              3             suffix              suffix      0        0  ...   \n",
       "3           3422          nonconcat             apocope      0        0  ...   \n",
       "4           2471            simplex      native_simplex      0        0  ...   \n",
       "...          ...                ...                 ...    ...      ...  ...   \n",
       "4995        1431          nonconcat             apocope      0        0  ...   \n",
       "4996        2775            simplex           borrowing      0        0  ...   \n",
       "4997       60875             suffix              suffix      0        0  ...   \n",
       "4998        2889            simplex           borrowing      0        0  ...   \n",
       "4999        2965            simplex           borrowing      0        0  ...   \n",
       "\n",
       "     autonomous_base base_stem_phon sfx_allomorph der_stem_phon edit_distance  \\\n",
       "0                NaN            NaN           NaN           NaN           NaN   \n",
       "1               True            kuʁ            ɔ̃          kɔʁt             2   \n",
       "2               True        UNKNOWN            yʃ           dab       UNKNOWN   \n",
       "3                NaN            NaN           NaN           NaN           NaN   \n",
       "4                NaN            NaN           NaN           NaN           NaN   \n",
       "...              ...            ...           ...           ...           ...   \n",
       "4995             NaN            NaN           NaN           NaN           NaN   \n",
       "4996             NaN            NaN           NaN           NaN           NaN   \n",
       "4997            True            sOv            aʒ         sOvət             2   \n",
       "4998             NaN            NaN           NaN           NaN           NaN   \n",
       "4999             NaN            NaN           NaN           NaN           NaN   \n",
       "\n",
       "         pattern pattern_tf     pattern_rel_tf       base_der_sim  \\\n",
       "0            NaN        NaN                NaN                NaN   \n",
       "1     _u_~_ɔ_tɔ̃          1           0.015625  0.222162783145905   \n",
       "2        UNKNOWN    UNKNOWN            UNKNOWN            UNKNOWN   \n",
       "3            NaN        NaN                NaN                NaN   \n",
       "4            NaN        NaN                NaN                NaN   \n",
       "...          ...        ...                ...                ...   \n",
       "4995         NaN        NaN                NaN                NaN   \n",
       "4996         NaN        NaN                NaN                NaN   \n",
       "4997     _~_ətaʒ          1  0.011494252873563  0.252674728631973   \n",
       "4998         NaN        NaN                NaN                NaN   \n",
       "4999         NaN        NaN                NaN                NaN   \n",
       "\n",
       "             offset_sim  \n",
       "0                   NaN  \n",
       "1     0.158108526129264  \n",
       "2               UNKNOWN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "...                 ...  \n",
       "4995                NaN  \n",
       "4996                NaN  \n",
       "4997  0.614848479997584  \n",
       "4998                NaN  \n",
       "4999                NaN  \n",
       "\n",
       "[4534 rows x 25 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "echantinom = pd.read_csv('../data/Echantinom-full-20210902.csv')\n",
    "echantinom = echantinom[~echantinom['lemma'].isin(nlexique[nlexique['gen'] == 'b']['lexeme'])] #[['lemma', 'phon', 'gen']]\n",
    "echantinom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>orth_pred</th>\n",
       "      <th>true</th>\n",
       "      <th>Class Probabilities</th>\n",
       "      <th>Set</th>\n",
       "      <th>Run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>an</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>[('n', {'f': 0.4085073173046112, 'm': 0.591492...</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bi</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>[('i', {'f': 0.16074861586093903, 'm': 0.83925...</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>[('s', {'f': 0.2868475317955017, 'm': 0.713152...</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>té</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>[('é', {'f': 0.3696044683456421, 'm': 0.630395...</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pie</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>[('e', {'f': 0.11107771843671799, 'm': 0.88892...</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45315</th>\n",
       "      <td>approvisionnement</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>[('t', {'f': 0.07809196412563324, 'm': 0.92190...</td>\n",
       "      <td>test</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45316</th>\n",
       "      <td>sous-alimentation</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>[('n', {'f': 0.38623788952827454, 'm': 0.61376...</td>\n",
       "      <td>test</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45317</th>\n",
       "      <td>cul-de-basse-fosse</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>[('e', {'f': 0.23680555820465088, 'm': 0.76319...</td>\n",
       "      <td>test</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45318</th>\n",
       "      <td>marie-couche-toi-là</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>[('à', {'f': 0.28149473667144775, 'm': 0.71850...</td>\n",
       "      <td>test</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45319</th>\n",
       "      <td>transsubstantiation</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>[('n', {'f': 0.38623788952827454, 'm': 0.61376...</td>\n",
       "      <td>test</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45320 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lemma orth_pred true  \\\n",
       "0                       an         m    m   \n",
       "1                       bi         m    m   \n",
       "2                       as         m    m   \n",
       "3                       té         m    m   \n",
       "4                      pie         f    f   \n",
       "...                    ...       ...  ...   \n",
       "45315    approvisionnement         m    m   \n",
       "45316    sous-alimentation         f    f   \n",
       "45317   cul-de-basse-fosse         m    m   \n",
       "45318  marie-couche-toi-là         f    f   \n",
       "45319  transsubstantiation         f    f   \n",
       "\n",
       "                                     Class Probabilities   Set  Run  \n",
       "0      [('n', {'f': 0.4085073173046112, 'm': 0.591492...  test    1  \n",
       "1      [('i', {'f': 0.16074861586093903, 'm': 0.83925...  test    1  \n",
       "2      [('s', {'f': 0.2868475317955017, 'm': 0.713152...  test    1  \n",
       "3      [('é', {'f': 0.3696044683456421, 'm': 0.630395...  test    1  \n",
       "4      [('e', {'f': 0.11107771843671799, 'm': 0.88892...  test    1  \n",
       "...                                                  ...   ...  ...  \n",
       "45315  [('t', {'f': 0.07809196412563324, 'm': 0.92190...  test   10  \n",
       "45316  [('n', {'f': 0.38623788952827454, 'm': 0.61376...  test   10  \n",
       "45317  [('e', {'f': 0.23680555820465088, 'm': 0.76319...  test   10  \n",
       "45318  [('à', {'f': 0.28149473667144775, 'm': 0.71850...  test   10  \n",
       "45319  [('n', {'f': 0.38623788952827454, 'm': 0.61376...  test   10  \n",
       "\n",
       "[45320 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orth_preds_x10 = pd.read_csv('../results/echantinom_orth_preds_x10.csv')\n",
    "orth_preds_x10.rename(columns={\"Predicted Gender\": \"orth_pred\", \"True Gender\": \"true\", \"Form\": 'lemma'}, inplace=True)\n",
    "orth_preds_x10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthographic error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correct and wrong orthographic predictions per gender:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>f_true</th>\n",
       "      <th>m_true</th>\n",
       "      <th>f_false</th>\n",
       "      <th>m_false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1446</td>\n",
       "      <td>2674</td>\n",
       "      <td>199</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1435</td>\n",
       "      <td>2665</td>\n",
       "      <td>208</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1451</td>\n",
       "      <td>2663</td>\n",
       "      <td>210</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1402</td>\n",
       "      <td>2721</td>\n",
       "      <td>152</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1420</td>\n",
       "      <td>2692</td>\n",
       "      <td>181</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1437</td>\n",
       "      <td>2660</td>\n",
       "      <td>213</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1457</td>\n",
       "      <td>2645</td>\n",
       "      <td>228</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1446</td>\n",
       "      <td>2663</td>\n",
       "      <td>210</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1506</td>\n",
       "      <td>2585</td>\n",
       "      <td>288</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1479</td>\n",
       "      <td>2643</td>\n",
       "      <td>230</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run  f_true  m_true  f_false  m_false\n",
       "0    1    1446    2674      199      213\n",
       "1    2    1435    2665      208      224\n",
       "2    3    1451    2663      210      208\n",
       "3    4    1402    2721      152      257\n",
       "4    5    1420    2692      181      239\n",
       "5    6    1437    2660      213      222\n",
       "6    7    1457    2645      228      202\n",
       "7    8    1446    2663      210      213\n",
       "8    9    1506    2585      288      153\n",
       "9   10    1479    2643      230      180"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>f_true</th>\n",
       "      <th>m_true</th>\n",
       "      <th>f_false</th>\n",
       "      <th>m_false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run  f_true  m_true  f_false  m_false\n",
       "0    1   0.879   0.926    0.121    0.074\n",
       "1    2   0.873   0.922    0.127    0.078\n",
       "2    3   0.874   0.928    0.126    0.072\n",
       "3    4   0.902   0.914    0.098    0.086\n",
       "4    5   0.887   0.918    0.113    0.082\n",
       "5    6   0.871   0.923    0.129    0.077\n",
       "6    7   0.865   0.929    0.135    0.071\n",
       "7    8   0.873   0.926    0.127    0.074\n",
       "8    9   0.839   0.944    0.161    0.056\n",
       "9   10   0.865   0.936    0.135    0.064"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('\\nCorrect and wrong orthographic predictions per gender:')\n",
    "# print(get_correct_wrong_pred_df(orth_preds_x10, proportions=False).to_markdown(index=False))\n",
    "distributions = get_correct_wrong_pred_df(orth_preds_x10, pred_col='orth_pred', proportions=False)\n",
    "distributions_prop = get_correct_wrong_pred_df(orth_preds_x10, pred_col='orth_pred', proportions=True)\n",
    "display(distributions, distributions_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### last_process_broad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender partition for last_process_broad over all runs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_true</th>\n",
       "      <th>m_true</th>\n",
       "      <th>f_false</th>\n",
       "      <th>m_false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_process_broad</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simplex</th>\n",
       "      <td>689</td>\n",
       "      <td>1254</td>\n",
       "      <td>98</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suffix</th>\n",
       "      <td>608</td>\n",
       "      <td>1092</td>\n",
       "      <td>62</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion</th>\n",
       "      <td>166</td>\n",
       "      <td>307</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polylexical</th>\n",
       "      <td>78</td>\n",
       "      <td>161</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonconcat</th>\n",
       "      <td>39</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prefix</th>\n",
       "      <td>28</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    f_true  m_true  f_false  m_false\n",
       "last_process_broad                                  \n",
       "simplex                689    1254       98      114\n",
       "suffix                 608    1092       62       84\n",
       "conversion             166     307       19       20\n",
       "polylexical             78     161        8       10\n",
       "nonconcat               39      57        3        9\n",
       "prefix                  28      53        6        7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_true</th>\n",
       "      <th>m_true</th>\n",
       "      <th>f_false</th>\n",
       "      <th>m_false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_process_broad</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simplex</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suffix</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polylexical</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonconcat</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prefix</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    f_true  m_true  f_false  m_false\n",
       "last_process_broad                                  \n",
       "simplex              0.875   0.917    0.125    0.083\n",
       "suffix               0.907   0.929    0.093    0.071\n",
       "conversion           0.897   0.939    0.103    0.061\n",
       "polylexical          0.907   0.942    0.093    0.058\n",
       "nonconcat            0.929   0.864    0.071    0.136\n",
       "prefix               0.824   0.883    0.176    0.117"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "category = 'last_process_broad' \n",
    "print(f\"\\nGender partition for {category} over all runs:\")\n",
    "all_runs = get_category_gender_partition(category, echantinom, orth_preds_x10, pred_col='orth_pred')\n",
    "all_runs_proportions = get_category_gender_partition(category, echantinom, orth_preds_x10, pred_col='orth_pred', proportion=True)\n",
    "display(all_runs, all_runs_proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [Run 1] Gender partition for last_process_broad:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_true</th>\n",
       "      <th>m_true</th>\n",
       "      <th>f_false</th>\n",
       "      <th>m_false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_process_broad</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simplex</th>\n",
       "      <td>635</td>\n",
       "      <td>1117</td>\n",
       "      <td>92</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suffix</th>\n",
       "      <td>565</td>\n",
       "      <td>963</td>\n",
       "      <td>53</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion</th>\n",
       "      <td>159</td>\n",
       "      <td>285</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polylexical</th>\n",
       "      <td>74</td>\n",
       "      <td>144</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonconcat</th>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prefix</th>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    f_true  m_true  f_false  m_false\n",
       "last_process_broad                                  \n",
       "simplex                635    1117       92       87\n",
       "suffix                 565     963       53       70\n",
       "conversion             159     285       16       15\n",
       "polylexical             74     144        8        8\n",
       "nonconcat               34      50        3        6\n",
       "prefix                  25      51        6        5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_true</th>\n",
       "      <th>m_true</th>\n",
       "      <th>f_false</th>\n",
       "      <th>m_false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_process_broad</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simplex</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suffix</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polylexical</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonconcat</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prefix</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    f_true  m_true  f_false  m_false\n",
       "last_process_broad                                  \n",
       "simplex              0.873   0.928    0.127    0.072\n",
       "suffix               0.914   0.932    0.086    0.068\n",
       "conversion           0.909   0.950    0.091    0.050\n",
       "polylexical          0.902   0.947    0.098    0.053\n",
       "nonconcat            0.919   0.893    0.081    0.107\n",
       "prefix               0.806   0.911    0.194    0.089"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = 1\n",
    "\n",
    "print(f\"\\n [Run {run}] Gender partition for {category}:\")\n",
    "run1 = get_category_gender_partition(category, echantinom, orth_preds_x10, pred_col='orth_pred', run=run)\n",
    "run1_prop = get_category_gender_partition(category, echantinom, orth_preds_x10, pred_col='orth_pred', run=run, proportion=True)\n",
    "display(run1, run1_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_process_broad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_data = orth_preds_x10[orth_preds_x10['Run'] == 3]\n",
    "crosstab = pd.crosstab(echantinom['last_process_broad'], run_data['true'])\n",
    "# TODO: why nothing from run 3 onwards?\n",
    "crosstab = crosstab.loc[crosstab.sum(axis=1).sort_values(ascending=False).index]\n",
    "crosstab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_process_broad\n",
       "simplex        138\n",
       "polylexical     19\n",
       "suffix          15\n",
       "conversion      13\n",
       "nonconcat        8\n",
       "prefix           6\n",
       "Name: lemma, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = 1\n",
    "pred_gender = 'f'\n",
    "true_gender = 'm'\n",
    "category = 'last_process_broad'\n",
    "\n",
    "f_false_rows = orth_preds_x10[(orth_preds_x10['Run'] == run) & (orth_preds_x10[\"orth_pred\"] == pred_gender) & (orth_preds_x10['true'] == true_gender)]\n",
    "\n",
    "# Merge the f_false_rows with the echantinom DataFrame to get the 'last_process_broad' column\n",
    "f_false_rows = f_false_rows.merge(echantinom[['lemma', category]], how='left', left_on='lemma', right_on='lemma')\n",
    "\n",
    "f_false_rows.groupby(category)['lemma'].count().sort_values(ascending=False)\n",
    "# f_false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exploring f_false:\n",
      "[Run 1] f_false simplex count: 138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['site', 'cube', 'mime', 'vice', 'vide', 'dine', 'vote', 'pèze',\n",
       "       'mile', 'cola', 'culte', 'drone', 'amble', 'limbe', 'nonce',\n",
       "       'monde', 'fifre', 'clone', 'ongle', 'nimbe', 'prote', 'torse',\n",
       "       'blase', 'palpe', 'galbe', 'renne', 'orgue', 'morse', 'birbe',\n",
       "       'tison', 'pence', 'grime', 'baile', 'gypse', 'angle', 'rifle',\n",
       "       'saule', 'arôme', 'kyrie', 'sauna', 'drive', 'tulle', 'sosie',\n",
       "       'gamma', 'pagne', 'agrume', 'prêche', 'caïque', 'vergne', 'litige',\n",
       "       'madère', 'porche', 'baffle', 'pulque', 'curare', 'flegme',\n",
       "       'cigare', 'lierre', 'calque', 'latino', 'buffle', 'cirque',\n",
       "       'casque', 'poison', 'stupre', 'couple', 'junkie', 'rallye',\n",
       "       'druide', 'cierge', 'congre', 'zouave', 'lambda', 'chèche',\n",
       "       'drille', 'bidule', 'causse', 'comble', 'jacques', 'vampire',\n",
       "       'tumulte', 'bidasse', 'bacille', 'guinche', 'concile', 'frisbee',\n",
       "       'silence', 'gruyère', 'emblème', 'fourgue', 'gymnase', 'marsala',\n",
       "       'braille', 'murmure', 'salaire', 'bouddha', 'symbole', 'falbala',\n",
       "       'flingue', 'mercure', 'bastion', 'vacarme', 'bazooka', 'chevesne',\n",
       "       'folklore', 'cantique', 'grimoire', 'quarante', 'genièvre',\n",
       "       'conclave', 'narcisse', 'margrave', 'triomphe', 'scarabée',\n",
       "       'barbecue', 'carrosse', 'brahmane', 'matamore', 'centurion',\n",
       "       'lentisque', 'macintosh', 'dies irae', 'cimetière', 'grotesque',\n",
       "       'champagne', 'mollusque', 'bourgogne', 'astragale', 'appendice',\n",
       "       'vestibule', 'dentifrice', 'chinchilla', 'bastringue',\n",
       "       'interstice', 'macfarlane', 'cheese-cake', 'strip-tease',\n",
       "       'archimandrite'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'simplex'\n",
    "\n",
    "print(f'\\nExploring {pred_gender}_false:')\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "# TODO: 138 rows where we're supposed to get 92 f_false\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false polylexical count: 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['adverbe', 'fanzine', 'confrère', 'unetelle', 'discobole',\n",
       "       'bidonville', 'bain-marie', 'passe-droit', 'saint-pierre',\n",
       "       'portefeuille', 'chasse-neige', 'faire-valoir', 'claque-merde',\n",
       "       'mille-feuille', 'chèvrefeuille', 'soutien-gorge', 'croquemitaine',\n",
       "       'homme-grenouille', 'contre-la-montre'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'polylexical'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false suffix count: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['ovule', 'butane', 'nivôse', 'pendule', 'sulfure', 'cyanure',\n",
       "       'lactose', 'ventôse', 'lignite', 'globule', 'caniche', 'fascicule',\n",
       "       'demandeur', 'capitaine', 'nourrisson'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'suffix'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false conversion count: 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['onze', 'sauté', 'double', 'balaise', 'parjure', 'atlante',\n",
       "       'immeuble', 'uniforme', 'acquitté', 'burlesque', 'maxillaire',\n",
       "       'plantigrade', 'barbiturique'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'conversion'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exploring m_false:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "last_process_broad\n",
       "simplex        147\n",
       "suffix          27\n",
       "nonconcat       14\n",
       "polylexical     12\n",
       "prefix           8\n",
       "conversion       5\n",
       "Name: lemma, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = 1\n",
    "pred_gender = 'm'\n",
    "true_gender = 'f'\n",
    "category = 'last_process_broad'\n",
    "\n",
    "print(f'\\nExploring {pred_gender}_false:')\n",
    "false_rows = orth_preds_x10[(orth_preds_x10['Run'] == run) & (orth_preds_x10[\"orth_pred\"] == pred_gender) & (orth_preds_x10['true'] == true_gender)]\n",
    "false_rows = false_rows.merge(echantinom[['lemma', category]], how='left', left_on='lemma', right_on='lemma')\n",
    "false_rows.groupby(category)['lemma'].count().sort_values(ascending=False)\n",
    "# false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false simplex count: 147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['foi', 'ire', 'nef', 'ive', 'glu', 'bru', 'obi', 'mer', 'clé',\n",
       "       'eau', 'cage', 'loge', 'robe', 'cour', 'soif', 'miss', 'care',\n",
       "       'tong', 'girl', 'part', 'gail', 'nage', 'rage', 'diva', 'toge',\n",
       "       'puce', 'zone', 'kipa', 'sape', 'hâte', 'city', 'soul', 'acre',\n",
       "       'cave', 'noix', 'gent', 'tribu', 'piste', 'câpre', 'douma',\n",
       "       'serre', 'façon', 'spore', 'hydre', 'pogne', 'bugle', 'fleur',\n",
       "       'corne', 'vodka', 'terre', 'vertu', 'bible', 'ancre', 'flore',\n",
       "       'brume', 'spire', 'bribe', 'alène', 'nacre', 'taule', 'jauge',\n",
       "       'grâce', 'plume', 'horde', 'kacha', 'smala', 'squaw', 'trame',\n",
       "       'savate', 'carène', 'satire', 'trique', 'huître', 'baraka',\n",
       "       'guenon', 'frange', 'truite', 'tumeur', 'sangle', 'capote',\n",
       "       'armada', 'razzia', 'pagode', 'strate', 'alcôve', 'galène',\n",
       "       'crypte', 'igname', 'cadène', 'poudre', 'brebis', 'gabare',\n",
       "       'bastos', 'lymphe', 'pin-up', 'cloque', 'rumeur', 'vahiné',\n",
       "       'fenêtre', 'syllabe', 'pirogue', 'mormone', 'arnaque', 'cuiller',\n",
       "       'septime', 'riposte', 'tartane', 'bagarre', 'canasta', 'victime',\n",
       "       'imposte', 'horloge', 'couleur', 'attaque', 'mandore', 'fanfare',\n",
       "       'chicane', 'enclume', 'crapule', 'algèbre', 'applique', 'victoire',\n",
       "       'calbombe', 'histoire', 'vertèbre', 'alhambra', 'panthère',\n",
       "       'start-up', 'fantasia', 'maharani', 'rhubarbe', 'williams',\n",
       "       'harangue', 'chasuble', 'vindicte', 'carouble', 'supplique',\n",
       "       'superstar', 'amaryllis', 'mangouste', 'mandibule', 'langouste',\n",
       "       'trattoria', 'stalagmite', 'chrysalide', 'escarboucle',\n",
       "       'garden-party'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'simplex'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false suffix count: 27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['catin', 'sueur', 'pudeur', 'fureur', 'piqûre', 'levure',\n",
       "       'vigueur', 'parenté', 'candeur', 'minceur', 'ferveur', 'boisson',\n",
       "       'louange', 'chanson', 'chaleur', 'rondeur', 'blondeur', 'noirceur',\n",
       "       'passoire', 'rousseur', 'grandeur', 'splendeur', 'blancheur',\n",
       "       'bronchite', 'corpuscule', 'bassinoire', 'rôtissoire'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'suffix'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false nonconcat count: 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['mob', 'info', 'cata', 'keuf', 'mayo', 'diapo', 'conso', 'impro',\n",
       "       'philo', 'nympho', 'porcif', 'nounou', 'dondon', 'thalasso'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'nonconcat'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false polylexical count: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['madame', 'silicone', 'parabole', 'bande-son', 'pause-café',\n",
       "       'notre-dame', \"presqu'île\", 'claire-voie', 'flanc-garde',\n",
       "       'grand-route', 'grand-voile', 'tête-de-mort'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'polylexical'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### last_process_narrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender partition for last_process_narrow over all runs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_true</th>\n",
       "      <th>m_true</th>\n",
       "      <th>f_false</th>\n",
       "      <th>m_false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_process_narrow</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>suffix</th>\n",
       "      <td>608</td>\n",
       "      <td>1092</td>\n",
       "      <td>62.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native_simplex</th>\n",
       "      <td>504</td>\n",
       "      <td>935</td>\n",
       "      <td>78.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borrowing</th>\n",
       "      <td>144</td>\n",
       "      <td>265</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-A</th>\n",
       "      <td>139</td>\n",
       "      <td>231</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native_compound</th>\n",
       "      <td>46</td>\n",
       "      <td>101</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prefix</th>\n",
       "      <td>28</td>\n",
       "      <td>53</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antonomasia</th>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neoclassical_compound</th>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agglomerate</th>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apocope</th>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-V12</th>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-V0</th>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduplication</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apocope_with_appendix</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-V13</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-VINF</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onomatopeic</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>procope</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blend</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-N</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-ADV</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-V</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verlan</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-PRO</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acronym</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louchébem</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-NUM</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       f_true  m_true  f_false  m_false\n",
       "last_process_narrow                                    \n",
       "suffix                    608    1092     62.0     84.0\n",
       "native_simplex            504     935     78.0     89.0\n",
       "borrowing                 144     265     18.0     22.0\n",
       "conversion-A              139     231     14.0     18.0\n",
       "native_compound            46     101      6.0      7.0\n",
       "prefix                     28      53      6.0      7.0\n",
       "antonomasia                38      50      2.0      2.0\n",
       "neoclassical_compound      14      28      1.0      3.0\n",
       "agglomerate                17      25      1.0      0.0\n",
       "apocope                    13      28      1.0      0.0\n",
       "conversion-V12              6      28      2.0      1.0\n",
       "conversion-V0              11      22      2.0      0.0\n",
       "reduplication              13      13      0.0      5.0\n",
       "apocope_with_appendix       9      11      1.0      3.0\n",
       "conversion-V13              2      11      0.0      0.0\n",
       "conversion-VINF             2       6      0.0      0.0\n",
       "onomatopeic                 3       4      0.0      1.0\n",
       "procope                     3       2      1.0      1.0\n",
       "blend                       1       5      0.0      0.0\n",
       "conversion-N                2       2      0.0      1.0\n",
       "conversion-ADV              2       3      0.0      0.0\n",
       "conversion-V                2       2      0.0      0.0\n",
       "verlan                      1       2      0.0      0.0\n",
       "conversion-PRO              0       1      1.0      0.0\n",
       "acronym                     0       2      0.0      0.0\n",
       "louchébem                   0       1      0.0      0.0\n",
       "conversion-NUM              0       1      0.0      0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_true</th>\n",
       "      <th>m_true</th>\n",
       "      <th>f_false</th>\n",
       "      <th>m_false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_process_narrow</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>suffix</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native_simplex</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borrowing</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-A</th>\n",
       "      <td>0.908</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native_compound</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prefix</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antonomasia</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neoclassical_compound</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agglomerate</th>\n",
       "      <td>0.944</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apocope</th>\n",
       "      <td>0.929</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-V12</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-V0</th>\n",
       "      <td>0.846</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduplication</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apocope_with_appendix</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-V13</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-VINF</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onomatopeic</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>procope</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blend</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-N</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-ADV</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-V</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verlan</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-PRO</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acronym</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louchébem</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion-NUM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       f_true  m_true  f_false  m_false\n",
       "last_process_narrow                                    \n",
       "suffix                  0.907   0.929    0.093    0.071\n",
       "native_simplex          0.866   0.913    0.134    0.087\n",
       "borrowing               0.889   0.923    0.111    0.077\n",
       "conversion-A            0.908   0.928    0.092    0.072\n",
       "native_compound         0.885   0.935    0.115    0.065\n",
       "prefix                  0.824   0.883    0.176    0.117\n",
       "antonomasia             0.950   0.962    0.050    0.038\n",
       "neoclassical_compound   0.933   0.903    0.067    0.097\n",
       "agglomerate             0.944   1.000    0.056    0.000\n",
       "apocope                 0.929   1.000    0.071    0.000\n",
       "conversion-V12          0.750   0.966    0.250    0.034\n",
       "conversion-V0           0.846   1.000    0.154    0.000\n",
       "reduplication           1.000   0.722    0.000    0.278\n",
       "apocope_with_appendix   0.900   0.786    0.100    0.214\n",
       "conversion-V13          1.000   1.000    0.000    0.000\n",
       "conversion-VINF         1.000   1.000    0.000    0.000\n",
       "onomatopeic             1.000   0.800    0.000    0.200\n",
       "procope                 0.750   0.667    0.250    0.333\n",
       "blend                   1.000   1.000    0.000    0.000\n",
       "conversion-N            1.000   0.667    0.000    0.333\n",
       "conversion-ADV          1.000   1.000    0.000    0.000\n",
       "conversion-V            1.000   1.000    0.000    0.000\n",
       "verlan                  1.000   1.000    0.000    0.000\n",
       "conversion-PRO          0.000   1.000    1.000    0.000\n",
       "acronym                   NaN   1.000      NaN    0.000\n",
       "louchébem                 NaN   1.000      NaN    0.000\n",
       "conversion-NUM            NaN   1.000      NaN    0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "category = 'last_process_narrow' \n",
    "print(f\"\\nGender partition for {category} over all runs:\")\n",
    "all_runs = get_category_gender_partition(category, echantinom, orth_preds_x10, pred_col='orth_pred')\n",
    "all_runs_proportions = get_category_gender_partition(category, echantinom, orth_preds_x10, pred_col='orth_pred', proportion=True)\n",
    "display(all_runs, all_runs_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_process_narrow\n",
       "native_simplex           103\n",
       "borrowing                 22\n",
       "suffix                    15\n",
       "antonomasia               13\n",
       "native_compound           13\n",
       "conversion-A              12\n",
       "prefix                     6\n",
       "apocope                    3\n",
       "apocope_with_appendix      3\n",
       "neoclassical_compound      3\n",
       "agglomerate                2\n",
       "blend                      1\n",
       "conversion-NUM             1\n",
       "procope                    1\n",
       "reduplication              1\n",
       "Name: lemma, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = 1\n",
    "pred_gender = 'f'\n",
    "true_gender = 'm'\n",
    "category = 'last_process_narrow'\n",
    "\n",
    "f_false_rows = orth_preds_x10[(orth_preds_x10['Run'] == run) & (orth_preds_x10[\"orth_pred\"] == pred_gender) & (orth_preds_x10['true'] == true_gender)]\n",
    "f_false_rows = f_false_rows.merge(echantinom[['lemma', category]], how='left', left_on='lemma', right_on='lemma')\n",
    "\n",
    "f_false_rows.groupby(category)['lemma'].count().sort_values(ascending=False)\n",
    "# f_false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false native_simplex count: 103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['site', 'cube', 'mime', 'vice', 'vide', 'dine', 'vote', 'pèze',\n",
       "       'mile', 'culte', 'drone', 'amble', 'limbe', 'nonce', 'monde',\n",
       "       'fifre', 'clone', 'ongle', 'nimbe', 'prote', 'torse', 'blase',\n",
       "       'palpe', 'galbe', 'renne', 'orgue', 'morse', 'birbe', 'tison',\n",
       "       'grime', 'baile', 'gypse', 'angle', 'saule', 'arôme', 'tulle',\n",
       "       'pagne', 'agrume', 'prêche', 'vergne', 'litige', 'porche',\n",
       "       'curare', 'flegme', 'cigare', 'lierre', 'calque', 'buffle',\n",
       "       'cirque', 'casque', 'poison', 'stupre', 'couple', 'druide',\n",
       "       'cierge', 'congre', 'zouave', 'chèche', 'drille', 'bidule',\n",
       "       'causse', 'comble', 'vampire', 'tumulte', 'bidasse', 'bacille',\n",
       "       'guinche', 'concile', 'silence', 'emblème', 'fourgue', 'gymnase',\n",
       "       'murmure', 'salaire', 'symbole', 'falbala', 'flingue', 'bastion',\n",
       "       'vacarme', 'chevesne', 'cantique', 'grimoire', 'quarante',\n",
       "       'genièvre', 'conclave', 'margrave', 'triomphe', 'scarabée',\n",
       "       'carrosse', 'brahmane', 'centurion', 'lentisque', 'cimetière',\n",
       "       'grotesque', 'mollusque', 'astragale', 'appendice', 'vestibule',\n",
       "       'dentifrice', 'chinchilla', 'bastringue', 'interstice',\n",
       "       'archimandrite'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'native_simplex'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false borrowing count: 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['cola', 'pence', 'rifle', 'kyrie', 'sauna', 'drive', 'gamma',\n",
       "       'caïque', 'baffle', 'pulque', 'latino', 'junkie', 'rallye',\n",
       "       'lambda', 'frisbee', 'bouddha', 'bazooka', 'folklore', 'barbecue',\n",
       "       'dies irae', 'cheese-cake', 'strip-tease'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'borrowing'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false suffix count: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['ovule', 'butane', 'nivôse', 'pendule', 'sulfure', 'cyanure',\n",
       "       'lactose', 'ventôse', 'lignite', 'globule', 'caniche', 'fascicule',\n",
       "       'demandeur', 'capitaine', 'nourrisson'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'suffix'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false antonomasia count: 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['sosie', 'madère', 'jacques', 'gruyère', 'marsala', 'braille',\n",
       "       'mercure', 'narcisse', 'matamore', 'macintosh', 'champagne',\n",
       "       'bourgogne', 'macfarlane'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'antonomasia'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false native_compound count: 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['bidonville', 'bain-marie', 'passe-droit', 'saint-pierre',\n",
       "       'portefeuille', 'chasse-neige', 'faire-valoir', 'claque-merde',\n",
       "       'mille-feuille', 'chèvrefeuille', 'soutien-gorge', 'croquemitaine',\n",
       "       'homme-grenouille'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'native_compound'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false conversion-A count: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['sauté', 'double', 'balaise', 'parjure', 'atlante', 'immeuble',\n",
       "       'uniforme', 'acquitté', 'burlesque', 'maxillaire', 'plantigrade',\n",
       "       'barbiturique'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'conversion-A'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false prefix count: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['vicomte', 'tricorne', 'demi-frère', 'entrecuisse', 'arrière-goût',\n",
       "       'contrepoison'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'prefix'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_process_narrow\n",
       "native_simplex           118\n",
       "borrowing                 27\n",
       "suffix                    27\n",
       "apocope                   10\n",
       "prefix                     8\n",
       "native_compound            7\n",
       "conversion-A               5\n",
       "agglomerate                3\n",
       "antonomasia                2\n",
       "neoclassical_compound      2\n",
       "reduplication              2\n",
       "apocope_with_appendix      1\n",
       "verlan                     1\n",
       "Name: lemma, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = 1\n",
    "pred_gender = 'm'\n",
    "true_gender = 'f'\n",
    "category = 'last_process_narrow'\n",
    "\n",
    "f_false_rows = orth_preds_x10[(orth_preds_x10['Run'] == run) & (orth_preds_x10[\"orth_pred\"] == pred_gender) & (orth_preds_x10['true'] == true_gender)]\n",
    "\n",
    "# Merge the f_false_rows with the echantinom DataFrame to get the 'last_process_broad' column\n",
    "f_false_rows = f_false_rows.merge(echantinom[['lemma', category]], how='left', left_on='lemma', right_on='lemma')\n",
    "\n",
    "f_false_rows.groupby(category)['lemma'].count().sort_values(ascending=False)\n",
    "# f_false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false native_simplex count: 118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['foi', 'ire', 'nef', 'ive', 'glu', 'bru', 'mer', 'clé', 'eau',\n",
       "       'cage', 'loge', 'robe', 'cour', 'soif', 'care', 'part', 'gail',\n",
       "       'nage', 'rage', 'toge', 'puce', 'zone', 'sape', 'hâte', 'acre',\n",
       "       'cave', 'noix', 'gent', 'tribu', 'piste', 'câpre', 'serre',\n",
       "       'façon', 'spore', 'hydre', 'pogne', 'bugle', 'fleur', 'corne',\n",
       "       'terre', 'vertu', 'bible', 'ancre', 'flore', 'brume', 'spire',\n",
       "       'bribe', 'alène', 'nacre', 'taule', 'jauge', 'grâce', 'plume',\n",
       "       'horde', 'trame', 'savate', 'carène', 'satire', 'trique', 'huître',\n",
       "       'guenon', 'frange', 'truite', 'tumeur', 'sangle', 'capote',\n",
       "       'pagode', 'strate', 'alcôve', 'galène', 'crypte', 'igname',\n",
       "       'cadène', 'poudre', 'brebis', 'gabare', 'lymphe', 'cloque',\n",
       "       'rumeur', 'fenêtre', 'syllabe', 'pirogue', 'arnaque', 'cuiller',\n",
       "       'septime', 'riposte', 'tartane', 'bagarre', 'victime', 'imposte',\n",
       "       'horloge', 'couleur', 'attaque', 'mandore', 'fanfare', 'chicane',\n",
       "       'enclume', 'crapule', 'algèbre', 'applique', 'victoire',\n",
       "       'calbombe', 'histoire', 'vertèbre', 'panthère', 'rhubarbe',\n",
       "       'harangue', 'chasuble', 'vindicte', 'carouble', 'supplique',\n",
       "       'amaryllis', 'mangouste', 'mandibule', 'langouste', 'stalagmite',\n",
       "       'chrysalide', 'escarboucle'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'native_simplex'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false borrowing count: 27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['obi', 'miss', 'tong', 'girl', 'diva', 'kipa', 'city', 'soul',\n",
       "       'douma', 'vodka', 'kacha', 'smala', 'squaw', 'baraka', 'armada',\n",
       "       'razzia', 'pin-up', 'vahiné', 'canasta', 'alhambra', 'start-up',\n",
       "       'fantasia', 'maharani', 'williams', 'superstar', 'trattoria',\n",
       "       'garden-party'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'borrowing'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false suffix count: 27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['catin', 'sueur', 'pudeur', 'fureur', 'piqûre', 'levure',\n",
       "       'vigueur', 'parenté', 'candeur', 'minceur', 'ferveur', 'boisson',\n",
       "       'louange', 'chanson', 'chaleur', 'rondeur', 'blondeur', 'noirceur',\n",
       "       'passoire', 'rousseur', 'grandeur', 'splendeur', 'blancheur',\n",
       "       'bronchite', 'corpuscule', 'bassinoire', 'rôtissoire'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'suffix'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false apocope count: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['mob', 'info', 'cata', 'mayo', 'diapo', 'conso', 'impro', 'philo',\n",
       "       'nympho', 'thalasso'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'apocope'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false prefix count: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['malfaçon', 'ex-femme', 'mi-pente', 'mini-jupe', 'mi-carême',\n",
       "       'mi-juillet', 'contrefaçon', 'avant-première'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'prefix'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender partition for compound over all runs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_true</th>\n",
       "      <th>m_true</th>\n",
       "      <th>f_false</th>\n",
       "      <th>m_false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1540</td>\n",
       "      <td>2774</td>\n",
       "      <td>188.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neoclassical</th>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB-NOUN</th>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN-NOUN</th>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ-NOUN</th>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN-ADJ</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ-ADJ</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB-ADV</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV-ADJ</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV-NOUN</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN-VERB</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB-VERB</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f_true  m_true  f_false  m_false\n",
       "compound                                      \n",
       "0               1540    2774    188.0    233.0\n",
       "neoclassical      20      42      1.0      4.0\n",
       "VERB-NOUN         15      33      4.0      3.0\n",
       "NOUN-NOUN         15      27      1.0      1.0\n",
       "ADJ-NOUN          11      24      1.0      2.0\n",
       "NOUN-ADJ           2      12      0.0      1.0\n",
       "ADJ-ADJ            1       4      0.0      0.0\n",
       "VERB-ADV           2       2      0.0      0.0\n",
       "ADV-ADJ            1       1      1.0      0.0\n",
       "ADV-NOUN           0       2      0.0      0.0\n",
       "NOUN-VERB          0       2      0.0      0.0\n",
       "VERB-VERB          1       1      0.0      0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_true</th>\n",
       "      <th>m_true</th>\n",
       "      <th>f_false</th>\n",
       "      <th>m_false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neoclassical</th>\n",
       "      <td>0.952</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB-NOUN</th>\n",
       "      <td>0.789</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN-NOUN</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ-NOUN</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN-ADJ</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ-ADJ</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB-ADV</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV-ADJ</th>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV-NOUN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN-VERB</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB-VERB</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f_true  m_true  f_false  m_false\n",
       "compound                                      \n",
       "0              0.891   0.923    0.109    0.077\n",
       "neoclassical   0.952   0.913    0.048    0.087\n",
       "VERB-NOUN      0.789   0.917    0.211    0.083\n",
       "NOUN-NOUN      0.938   0.964    0.062    0.036\n",
       "ADJ-NOUN       0.917   0.923    0.083    0.077\n",
       "NOUN-ADJ       1.000   0.923    0.000    0.077\n",
       "ADJ-ADJ        1.000   1.000    0.000    0.000\n",
       "VERB-ADV       1.000   1.000    0.000    0.000\n",
       "ADV-ADJ        0.500   1.000    0.500    0.000\n",
       "ADV-NOUN         NaN   1.000      NaN    0.000\n",
       "NOUN-VERB        NaN   1.000      NaN    0.000\n",
       "VERB-VERB      1.000   1.000    0.000    0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "category = 'compound' \n",
    "print(f\"\\nGender partition for {category} over all runs:\")\n",
    "all_runs = get_category_gender_partition(category, echantinom, orth_preds_x10, pred_col='orth_pred')\n",
    "all_runs_proportions = get_category_gender_partition(category, echantinom, orth_preds_x10, pred_col='orth_pred', proportion=True)\n",
    "display(all_runs, all_runs_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compound\n",
       "0               182\n",
       "VERB-NOUN         6\n",
       "NOUN-NOUN         5\n",
       "neoclassical      4\n",
       "ADJ-NOUN          1\n",
       "VERB-VERB         1\n",
       "Name: lemma, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = 1\n",
    "pred_gender = 'f'\n",
    "true_gender = 'm'\n",
    "category = 'compound'\n",
    "\n",
    "f_false_rows = orth_preds_x10[(orth_preds_x10['Run'] == run) & (orth_preds_x10[\"orth_pred\"] == pred_gender) & (orth_preds_x10['true'] == true_gender)]\n",
    "f_false_rows = f_false_rows.merge(echantinom[['lemma', category]], how='left', left_on='lemma', right_on='lemma')\n",
    "\n",
    "f_false_rows.groupby(category)['lemma'].count().sort_values(ascending=False)\n",
    "# f_false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false VERB-NOUN count: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['passe-droit', 'portefeuille', 'chasse-neige', 'claque-merde',\n",
       "       'soutien-gorge', 'croquemitaine'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'VERB-NOUN'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false NOUN-NOUN count: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['bidonville', 'bain-marie', 'saint-pierre', 'chèvrefeuille',\n",
       "       'homme-grenouille'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'NOUN-NOUN'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false neoclassical count: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['adverbe', 'confrère', 'discobole', 'plantigrade'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'neoclassical'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compound\n",
       "0               201\n",
       "neoclassical      5\n",
       "ADJ-NOUN          3\n",
       "NOUN-NOUN         3\n",
       "ADV-NOUN          1\n",
       "Name: lemma, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = 1\n",
    "pred_gender = 'm'\n",
    "true_gender = 'f'\n",
    "category = 'compound'\n",
    "\n",
    "f_false_rows = orth_preds_x10[(orth_preds_x10['Run'] == run) & (orth_preds_x10[\"orth_pred\"] == pred_gender) & (orth_preds_x10['true'] == true_gender)]\n",
    "f_false_rows = f_false_rows.merge(echantinom[['lemma', category]], how='left', left_on='lemma', right_on='lemma')\n",
    "\n",
    "f_false_rows.groupby(category)['lemma'].count().sort_values(ascending=False)\n",
    "# f_false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false neoclassical count: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['philo', 'nympho', 'thalasso', 'silicone', 'parabole'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'neoclassical'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false ADJ-NOUN count: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['claire-voie', 'grand-route', 'grand-voile'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'ADJ-NOUN'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false NOUN-NOUN count: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['bande-son', 'pause-café', 'flanc-garde'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'NOUN-NOUN'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suffix broad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender partition for suffix_broad over all runs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_true</th>\n",
       "      <th>m_true</th>\n",
       "      <th>f_false</th>\n",
       "      <th>m_false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suffix_broad</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930</td>\n",
       "      <td>1725</td>\n",
       "      <td>124.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eurM1</th>\n",
       "      <td>62</td>\n",
       "      <td>126</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ment</th>\n",
       "      <td>73</td>\n",
       "      <td>111</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ion</th>\n",
       "      <td>58</td>\n",
       "      <td>104</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ier</th>\n",
       "      <td>52</td>\n",
       "      <td>82</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aque</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ille</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>illon</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f_true  m_true  f_false  m_false\n",
       "suffix_broad                                  \n",
       "0                930    1725    124.0    148.0\n",
       "eurM1             62     126      9.0      9.0\n",
       "ment              73     111      8.0     10.0\n",
       "ion               58     104      3.0     11.0\n",
       "ier               52      82      3.0      7.0\n",
       "...              ...     ...      ...      ...\n",
       "en                 1       0      0.0      0.0\n",
       "one                0       1      0.0      0.0\n",
       "aque               1       0      0.0      0.0\n",
       "ille               1       0      0.0      0.0\n",
       "illon              0       1      0.0      0.0\n",
       "\n",
       "[90 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_true</th>\n",
       "      <th>m_true</th>\n",
       "      <th>f_false</th>\n",
       "      <th>m_false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suffix_broad</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eurM1</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ment</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ion</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ier</th>\n",
       "      <td>0.945</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aque</th>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ille</th>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>illon</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f_true  m_true  f_false  m_false\n",
       "suffix_broad                                  \n",
       "0              0.882   0.921    0.118    0.079\n",
       "eurM1          0.873   0.933    0.127    0.067\n",
       "ment           0.901   0.917    0.099    0.083\n",
       "ion            0.951   0.904    0.049    0.096\n",
       "ier            0.945   0.921    0.055    0.079\n",
       "...              ...     ...      ...      ...\n",
       "en             1.000     NaN    0.000      NaN\n",
       "one              NaN   1.000      NaN    0.000\n",
       "aque           1.000     NaN    0.000      NaN\n",
       "ille           1.000     NaN    0.000      NaN\n",
       "illon            NaN   1.000      NaN    0.000\n",
       "\n",
       "[90 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "category = 'suffix_broad' \n",
    "print(f\"\\nGender partition for {category} over all runs:\")\n",
    "all_runs = get_category_gender_partition(category, echantinom, orth_preds_x10, pred_col='orth_pred')\n",
    "all_runs_proportions = get_category_gender_partition(category, echantinom, orth_preds_x10, pred_col='orth_pred', proportion=True)\n",
    "display(all_runs, all_runs_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "suffix_broad\n",
       "0        181\n",
       "ule        3\n",
       "Vche       2\n",
       "ain        2\n",
       "ureM       2\n",
       "ôse        2\n",
       "aneM       1\n",
       "cule       1\n",
       "eurM1      1\n",
       "ique       1\n",
       "ite        1\n",
       "on         1\n",
       "ose        1\n",
       "Name: lemma, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = 1\n",
    "pred_gender = 'f'\n",
    "true_gender = 'm'\n",
    "category = 'suffix_broad'\n",
    "\n",
    "f_false_rows = orth_preds_x10[(orth_preds_x10['Run'] == run) & (orth_preds_x10[\"orth_pred\"] == pred_gender) & (orth_preds_x10['true'] == true_gender)]\n",
    "f_false_rows = f_false_rows.merge(echantinom[['lemma', category]], how='left', left_on='lemma', right_on='lemma')\n",
    "f_false_rows.groupby(category)['lemma'].count().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false ule count: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['ovule', 'pendule', 'globule'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'ule'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false Vche count: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['matuche', 'caniche'], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'Vche'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false ureM count: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['sulfure', 'cyanure'], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'ureM'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exploring m_false:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "suffix_broad\n",
       "0       182\n",
       "eurF     15\n",
       "onF       4\n",
       "oir       3\n",
       "ureF      2\n",
       "aire      1\n",
       "ange      1\n",
       "cule      1\n",
       "if        1\n",
       "in        1\n",
       "ite       1\n",
       "ité       1\n",
       "Name: lemma, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = 1\n",
    "pred_gender = 'm'\n",
    "true_gender = 'f'\n",
    "category = 'suffix_broad'\n",
    "\n",
    "print(f'\\nExploring {pred_gender}_false:')\n",
    "false_rows = orth_preds_x10[(orth_preds_x10['Run'] == run) & (orth_preds_x10[\"orth_pred\"] == pred_gender) & (orth_preds_x10['true'] == true_gender)]\n",
    "false_rows = false_rows.merge(echantinom[['lemma', category]], how='left', left_on='lemma', right_on='lemma')\n",
    "false_rows.groupby(category)['lemma'].count().sort_values(ascending=False)\n",
    "# false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false eurF count: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['sueur', 'pudeur', 'fureur', 'vigueur', 'candeur', 'minceur',\n",
       "       'ferveur', 'chaleur', 'rondeur', 'blondeur', 'noirceur',\n",
       "       'rousseur', 'grandeur', 'splendeur', 'blancheur'], dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'eurF'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false onF count: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['boisson', 'chanson', 'malfaçon', 'contrefaçon'], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'onF'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false oir count: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['passoire', 'bassinoire', 'rôtissoire'], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'oir'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender partition for conversion over all runs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_true</th>\n",
       "      <th>m_true</th>\n",
       "      <th>f_false</th>\n",
       "      <th>m_false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1151</td>\n",
       "      <td>2061</td>\n",
       "      <td>140.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V0</th>\n",
       "      <td>222</td>\n",
       "      <td>446</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>219</td>\n",
       "      <td>363</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VINF</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRO</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f_true  m_true  f_false  m_false\n",
       "conversion                                  \n",
       "0             1151    2061    140.0    177.0\n",
       "V0             222     446     32.0     32.0\n",
       "A              219     363     21.0     33.0\n",
       "V12              6      28      2.0      1.0\n",
       "V13              2      11      0.0      0.0\n",
       "VINF             2       6      0.0      0.0\n",
       "ADV              2       3      0.0      0.0\n",
       "N                2       2      0.0      1.0\n",
       "V                2       2      0.0      0.0\n",
       "PRO              0       1      1.0      0.0\n",
       "NUM              0       1      0.0      0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_true</th>\n",
       "      <th>m_true</th>\n",
       "      <th>f_false</th>\n",
       "      <th>m_false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V0</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VINF</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRO</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f_true  m_true  f_false  m_false\n",
       "conversion                                  \n",
       "0            0.892   0.921    0.108    0.079\n",
       "V0           0.874   0.933    0.126    0.067\n",
       "A            0.912   0.917    0.088    0.083\n",
       "V12          0.750   0.966    0.250    0.034\n",
       "V13          1.000   1.000    0.000    0.000\n",
       "VINF         1.000   1.000    0.000    0.000\n",
       "ADV          1.000   1.000    0.000    0.000\n",
       "N            1.000   0.667    0.000    0.333\n",
       "V            1.000   1.000    0.000    0.000\n",
       "PRO          0.000   1.000    1.000    0.000\n",
       "NUM            NaN   1.000      NaN    0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "category = 'conversion' \n",
    "print(f\"\\nGender partition for {category} over all runs:\")\n",
    "all_runs = get_category_gender_partition(category, echantinom, orth_preds_x10, pred_col='orth_pred')\n",
    "all_runs_proportions = get_category_gender_partition(category, echantinom, orth_preds_x10, pred_col='orth_pred', proportion=True)\n",
    "display(all_runs, all_runs_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conversion\n",
       "0      152\n",
       "V0      34\n",
       "A       12\n",
       "NUM      1\n",
       "Name: lemma, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = 1\n",
    "pred_gender = 'f'\n",
    "true_gender = 'm'\n",
    "category = 'conversion'\n",
    "\n",
    "f_false_rows = orth_preds_x10[(orth_preds_x10['Run'] == run) & (orth_preds_x10[\"orth_pred\"] == pred_gender) & (orth_preds_x10['true'] == true_gender)]\n",
    "f_false_rows = f_false_rows.merge(echantinom[['lemma', category]], how='left', left_on='lemma', right_on='lemma')\n",
    "\n",
    "f_false_rows.groupby(category)['lemma'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false V0 count: 34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['cube', 'mime', 'vice', 'vide', 'vote', 'pèze', 'amble', 'fifre',\n",
       "       'clone', 'nimbe', 'palpe', 'galbe', 'tison', 'grime', 'angle',\n",
       "       'prêche', 'calque', 'casque', 'couple', 'comble', 'sulfure',\n",
       "       'tumulte', 'guinche', 'silence', 'cyanure', 'fourgue', 'murmure',\n",
       "       'salaire', 'flingue', 'vacarme', 'triomphe', 'carrosse',\n",
       "       'matamore', 'bastringue'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'V0'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] f_false A count: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['sauté', 'double', 'balaise', 'parjure', 'atlante', 'immeuble',\n",
       "       'uniforme', 'acquitté', 'burlesque', 'maxillaire', 'plantigrade',\n",
       "       'barbiturique'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'A'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conversion\n",
       "0     158\n",
       "V0     48\n",
       "A       7\n",
       "Name: lemma, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = 1\n",
    "pred_gender = 'm'\n",
    "true_gender = 'f'\n",
    "category = 'conversion'\n",
    "\n",
    "f_false_rows = orth_preds_x10[(orth_preds_x10['Run'] == run) & (orth_preds_x10[\"orth_pred\"] == pred_gender) & (orth_preds_x10['true'] == true_gender)]\n",
    "f_false_rows = f_false_rows.merge(echantinom[['lemma', category]], how='left', left_on='lemma', right_on='lemma')\n",
    "\n",
    "f_false_rows.groupby(category)['lemma'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false V0 count: 48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['glu', 'loge', 'robe', 'soif', 'nage', 'rage', 'zone', 'sape',\n",
       "       'hâte', 'cave', 'piste', 'serre', 'façon', 'pogne', 'fleur',\n",
       "       'corne', 'terre', 'ancre', 'brume', 'nacre', 'jauge', 'grâce',\n",
       "       'plume', 'trame', 'carène', 'trique', 'frange', 'sangle', 'capote',\n",
       "       'poudre', 'cloque', 'levure', 'fenêtre', 'syllabe', 'arnaque',\n",
       "       'riposte', 'louange', 'bagarre', 'victime', 'couleur', 'attaque',\n",
       "       'fanfare', 'chicane', 'applique', 'histoire', 'vertèbre',\n",
       "       'silicone', 'harangue'], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'V0'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] m_false A count: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['nympho', 'dextre', 'mormone', 'secrète', 'bayadère', 'verticale',\n",
       "       'perpendiculaire'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategory = 'A'\n",
    "false_rows= get_false_preds(run, echantinom, 'orth_pred', pred_gender, true_gender, orth_preds_x10, category, subcategory)\n",
    "print(f\"[Run {run}] {pred_gender}_false {subcategory} count: {len(false_rows['lemma'].unique())}\")\n",
    "false_rows['lemma'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
